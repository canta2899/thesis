\label{ch:fall-detection}

With the purpose of providing a deeper understanding on how some of the most relevant datasets regarding fall detection were collected, an analysis was performed in order to identify common \textbf{patterns}, the \textbf{technologies} employed and the \textbf{results obtained}. 

\section{Typical biometric data employed in fall detection}\label{sec:hardware}

The consequences of falling may be observed through a series of data that addresses aspects related to physical, physiological and environmental variables. Some of the repercussions that a hard fall may cause are:

\begin{itemize}
    \item A fast shift of the gravitational acceleration values
    \item A change of the altitude above ground level
    \item Feelings of fear and obfuscation (especially for elderly people in severe cases)
    \item A decrease of the body temperature (in cases in which the individual remains prone on the ground for extended periods of time)
\end{itemize}

The following section introduces some of the most commonly used instruments to retrieve data that may be functional to fall detection systems.

\subsection{Accelerometer}\label{subsec:accelerometer}

The accelerometer provides a measure of the \textbf{acceleration} in relation to an entity in its coordinate system. Once calibrated, the obtained value measures 9.81 $m/s^2$ at rest (which corresponds to the gravity acceleration) and drops at 0 $m/s^2$ during a \textbf{free fall}.

Furthermore, modern accelerometer are commonly implemented as \emph{micro-electro-mechanical-systems} and their dimensions have packaged sizes of only 2 x 2 x 1 \textit{mm}. This makes them particularly suitable for \textbf{wearable devices} and \textbf{embedded systems}.

Since a 3-axis accelerometer provides a separate trace for the $x$, $y$ and $z$ axis, a \textbf{magnitude vector} can be computed in order to represent the measurement as a scalar value. The formula involves the calculation of the norm of the coordinate vector and is generally computed in real-time on embedded systems in order to provide a value for classification purposes.

\newcommand\norm[1]{\left\lVert#1\right\rVert}

\begin{figure}[h]
    \begin{equation}
    \norm{a}_2 = \sqrt{a_{x}^2 + a_{y}^2 + a_{z}^2}
    \end{equation}
    \caption{Magnitude Vector formula}
    \label{fig:magnitude}
\end{figure}

\subsection{9-Axis IMUs}\label{subsec:imus}

The \textbf{inertial motion sensor} units (commonly referred as IMUs) provide a combination of three sensors:

\begin{itemize}
    \item A 3-axis accelerometer
    \item A 3-axis gyroscope 
    \item A 3-axis magnetometer 
\end{itemize}

While the accelerometer and gyroscope signals provide measures to describe the \emph{rotation} and the \emph{acceleration} around each axis, a magnetometer is employed in order to sense the surrounding \emph{magnetic field} and correct small drifts over long lasting periods of time. 

The combination of the latter sources provides a criteria to compute the \textbf{complete orientation in space} and offers remarkable advantages in order to improve accuracy in motion tracking and fall detection systems.

\subsection{Barometric Altimeter}\label{subsec:altimeter}

The barometric altimeter determines changes in elevation by employing a pressure sensor. Compared to the changes in the atmospheric pressure, in fact, the altitude variation results inversely proportional \cite{mems-altimeter}.

Although barometric altimeters are involved in a multitude of usages, the data collected may provide useful information in the context of fall detection systems. The altitude level, when combined with the data retrieved from a 9-Axis IMU or an accelerometer, may confirm that a fall event just happened with higher levels of accuracy.

Several instruments for motion tracking include both a 9-Axis inertial measurement unit and a barometric altimeter. For that, they are commonly referred as \textbf{10-Axis IMUs}.

\subsection{Biometric Sensors}\label{subsec:biometric-sensors}

Another branch of information which has been widely regarded lately is related to biometric sensors. These include a variety of instruments to collect biometric signals by using appropriate hardware, such as \textbf{electrodes}, \textbf{skin contact technologies} and others.

Besides some units require the usage of specific hardware, other sensors (such as the ECG, EEG, Temperature, EDA and others) have already been implemented in several commercial wearable devices and provide accurate data that can later be involved in the computation of several biometric descriptors. 

In the context of fall detection systems, a synchronized retrieval of both biometric and motion related data may significantly improve the accuracy of classification models.

\section{Multimodal datasets for fall detection systems}\label{sec:datasets}

Despite the fact that various falls datasets have been made available throughout the years, two of them were selected for the purpose of this analysis as a consequence of their relevance in the research environment.

\subsection{UMAFall - A Multisensor Dataset for the Research on Automatic Fall Detection}\label{subsec:umafall}

The \textbf{UMAFall} dataset gained considerable interest since its publication (happened in 2017). The primary difference from other datasets was, in fact, related to the way Casilari \textit{et al., 2018}~\cite{umafall} approached the data collection stage, which involved the usage of multiple units of the same sensor. 

Basing on the conclusions drawn by previous publications, UMAFall was designed in order to provide a public dataset to study the importance of sensor units placement for the effectiveness of fall detection algorithms \cite{umafall}. The traces collected provide measurements of the mobility during daily life activities and falls, obtained by \textbf{five sensing nodes} placed on different positions of the body of several individuals.

\subsubsection{Technologies Involved}\label{subsubsec:umafall-technologies}

The data gathering architecture was implemented as a \textbf{Bluetooth Low Energy} (BLE) piconet composed of:

\begin{itemize}
    \item Four wearable sensors located in four different positions of the body, acting as \textbf{slave nodes}
    \item An Android smartphone, acting as the \textbf{master node}
\end{itemize}

The nodes were implemented through multiple \textbf{SimpleLink SensorTag} units. These consist of IoT devices powered by a CC2650 ARM microcontroller that integrates: 

\begin{itemize}
    \item a 2.4 GHz transceiver
    \item 10 embedded sensors, including an MPU-9250 multichip module
\end{itemize}

The latter made possible the retrieval of motion related data, combining the values registered by a 3-axis gyroscope, a 3-axis accelerometer and a 3-axis magnetometer, which were regularly sent to the master unit and later saved in a CSV file. However, the usage of the Bluetooth protocol has demanded low resolutions in order to avoid saturating the communication channel. Therefore, the \textbf{sample rate} was set to 20 Hz for each unit.

\subsubsection{Activities Performed}\label{subsubsec:umafall-activities}

The four sensors were placed on locations typically reported in literature, such as the ankle, waist, chest and right wrist. Furthermore, the participants consisted of seventeen individuals divided in ten males and seven females aged between 18 and 55 years old.

Because of the practical sensor architecture based on wearable devices, data could be retrieved in a domestic environment and included the activities reported in Table \ref{toc:umafall}

\begin{table}[H]
\centering
\begin{tabular}{ll}
    \hline
    Activity                & Category \\
    \hline
    Body bending            & Daily Activities \\
    Climbing stairs down    & Daily Activities \\
    Hopping                 & Daily Activities \\
    Light jogging           & Daily Activities \\
    Lying down              & Daily Activities \\
    Sitting down            & Daily Activities \\
    Walking                 & Daily Activities \\
    Forward fall            & Fall \\
    Later fall              & Fall \\
    Backwards fall          & Fall \\
    \hline
\end{tabular}
\caption{Activities evaluated in UMAFall}
\label{toc:umafall}
\end{table}

\subsubsection{Results Obtained}\label{subsubsec:umafall-results}

Casilari \textit{et al., 2018}~\cite{umafall} provided a dataset including 531 CSV files of which 322 were reporting daily activities data and 209 were reporting falls related data, each one of 15-seconds duration. An initial analysis was performed in order to describe the variation of the \textbf{Signal Magnitude Vector} for each dataset.

Lastly, the results obtained determined substantial difficulties in distinguishing falls from moderate activities using threshold based techniques. An approach based on the fusion of multiple sensor data and the usage of Machine Learning advances in order to reduce the number of \textbf{false positives} obtained was, lastly, proposed by the authors, but not implemented.

\subsection{UP-Fall Detection Dataset: A Multimodal Approach}\label{sec:upfall}

The \textbf{UP-Fall} dataset was presented in 2019 in order to collect fall-related information according to three major modalities:

\begin{itemize}
    \item \textbf{Wearable sensors}
    \item \textbf{Ambient sensors}
    \item \textbf{Vision devices}
\end{itemize}

The aim of the study was providing a considerable amount of data collected from heterogeneous sources in order to address the lack of publicly available measurements for the evaluation of fall detection systems \cite{upfall}.

\subsubsection{Technologies Involved}\label{subsubsec:upfall-technologies}

The hardware involved consisted of: 

\begin{itemize}
\item Five \textbf{Mbientlab MetaSensor} wearables located in different points of the body and collecting data from: 
    \begin{itemize}
        \item A 3-axis accelerometer
        \item A 3-axis gyroscope
        \item An ambient light sensor
    \end{itemize}
\item A \textbf{NeuroSky MindWave} electroencephalograph headset measuring the brainwave signal
\item Six \textbf{infrared sensors} forming a grid above the floor of the room
\item Two \textbf{Microsoft LifeCam Cinema} cameras providing a frontal and a lateral view of the individual 
\end{itemize}

The data gathering architecture was implemented through the usage of two computers and three Raspberry PI V3 in order to collect the information from all the sensors and later save it in the form of multiple CSV files.

In this case a sample rate of \~ 18.4 Hz was configured in order to accommodate the requirements of all the units involved.

\subsubsection{Activities Performed}\label{subsubsec:upfall-activities}

The UP-Fall dataset was collected in a \textbf{controlled environment} where 17 young and healthy subjects were required to perform 11 different activities with three attempts each \cite{upfall}.

\begin{table}[H]
\centering
\begin{tabular}{ll}
    \hline
    Activity                          &   Category           \\
    \hline
    Walking                           &   Daily Activities   \\
    Standing                          &   Daily Activities   \\
    Sitting                           &   Daily Activities   \\
    Picking up an Object              &   Daily Activities   \\
    Laying                            &   Daily Activities   \\
    Jumping                           &   Daily Activities   \\
    Falling sitting in empty chair    &   Fall               \\
    Falling sideward                  &   Fall               \\
    Falling backwards                 &   Fall               \\
    Falling forwards using knees      &   Fall               \\
    Falling forwards using hands      &   Fall               \\
    \hline
\end{tabular}
\caption{Activities evaluated in UP-Fall}
\label{toc:umafall2}
\end{table}

The raw gathered data was later divided in different time windows and, for each one of them, a \textbf{feature extraction and selection} process was performed. The processed information was, then, used to evaluate the performance of four classification models: 

\begin{itemize}
    \item Random Forest
    \item Support Vector Machines
    \item Multi-Layer Perceptron
    \item \textit{k}-Nearest Neighbors
\end{itemize}

The performances of the latter were evaluated through the metrics of \textit{accuracy}, \textit{precision}, \textit{sensitivity}, \textit{specificity} and $F_1$ - \textit{score}.

A limitation pointed out by the authors \cite{umafall} involves the context of the experimentation: the falls performed were self-initiated and different from real-life falls. These kind of aspects constitute a primary concern for researchers because of the difficulties in addressing them and the inaccuracy they might lead to, as stated in \ref{sec:fallintro}.

\subsubsection{Results Obtained}\label{subsubsec:upfall-results}

The dataset obtained and the following activities of processing and subsequent analysis performed led to observe that the data retrieved from the inertial measurement units of the wearables played a major role in the accuracy of the classification models. The accuracy (depicted by the $F_1$-score) of the IMUs-only based classification reached a value of 70.31\% while classifiers trained with combination of infrared and camera data demonstrated considerably lower performances (between 15\% and 33\%). Lastly, the combination of data collected by wearables, cameras and the EEG sensor obtained the highest $F_1$-score accuracy measure, which corresponded to 70.44\%. 

Additionally, a Convolutional Neural Network was trained in order to improve the classification performance based on video recording data. This reached an $F_1$-\textit{score} of 71.2\%.

In conclusion, in the context of fall detection systems, the analysis performed on the UP-Fall dataset demonstrated that a certain degree of accuracy may be reached by processing data from sources of different nature, even though classifications can be improved by approaching the subject in a multimodal and heterogeneous manner.

