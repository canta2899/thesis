\label{ch:analysis}

With the purpose of providing a deeper understanding of how some of the most relevant datasets regarding fall detection were collected, an analysis was performed in order to identify common \textbf{patterns}, the \textbf{technologies} employed and the \textbf{results obtained}. Afterwards, the previously mentioned \textbf{Electrodermal Activity} and its potential implications in the context of fall detection was investigated.

\section{Typical biometric data employed in fall detection}\label{sec:hardware}

To be written

\section{Multimodal datasets for fall detection systems}\label{sec:datasets}

Despite the fact that various falls datasets have been made available throughout the years, two of them were selected for the purpose of this analysis as a consequence of their relevance in the research environment.

\subsection{UMAFall - A Multisensor Dataset for the Research on Automatic Fall Detection}\label{subsec:umafall}

The \textbf{UMAFall} dataset gained considerable interest since its publication (happened in 2017). The primary difference from other datasets was, in fact, related to the way Casilari \textit{et al., 2018}~\cite{umafall} approached the data collection stage, which involved the usage of multiple units of the same sensor. 

Basing on the conclusions drawn by previous publications, UMAFall was designed in order to provide a public dataset to study the importance of sensor units' placement for the effectiveness of fall detection algorithms \cite{umafall}. The traces collected provide measurements of the mobility during daily life activities and falls, obtained by \textbf{five sensing nodes} places on different positions of the individual's body.

\subsubsection{Technologies Involved}\label{subsubsec:umafall-technologies}

The data gathering architecture was implemented as a \textbf{Bluetooth Low Energy} (BLE) piconet composed of:

\begin{itemize}
    \item Four wearable sensors located in four different positions of the body, acting as \textbf{slave nodes}
    \item An Android smartphone, acting as the \textbf{master node}
\end{itemize}

The nodes were implemented through multiple \textbf{SimpleLink SensorTag} units. These consist of IoT devices powered by a CC2650 ARM microcontroller that integrates: 

\begin{itemize}
    \item a 2.4 GHz transceiver
    \item 10 embedded sensors, including an MPU-9250 multichip module
\end{itemize}

The latter made possible the retrieval of motion related data, combining the values registered by a 3-axis gyroscope, a 3-axis accelerometer and a 3-axis magnetometer, which were regularly sent to the master unit and later saved in a CSV file. However, the usage of Bluetooth communications has demanded low resolutions in order to avoid the saturation of the communication channel. Therefore, the \textbf{sample rate} was set to 20 Hz for each sensor unit.

\subsubsection{Activities Performed}\label{subsubsec:umafall-activities}

The four sensors were placed on locations typically reported in literature, such as the ankle, waist, chest and right wrist. Furthermore, the participants consisted of seventeen users divided in ten males and seven females aged between 18 and 55 years old.

Because of the practical sensor architecture based on wearable devices, data could be retrieved in a domestic environment and included the activities reported in Table \ref{toc:umafall}

\begin{table}[H]
\centering
\begin{tabular}{ll}
    \hline
    Activity                & Category \\
    \hline
    Body bending            & Daily Activities \\
    Climbing stairs down    & Daily Activities \\
    Hopping                 & Daily Activities \\
    Light jogging           & Daily Activities \\
    Lying down              & Daily Activities \\
    Sitting down            & Daily Activities \\
    Walking                 & Daily Activities \\
    Forward fall            & Fall \\
    Later fall              & Fall \\
    Backwards fall          & Fall \\
    \hline
\end{tabular}
\caption{Activities evaluated in UMAFall}
\label{toc:umafall}
\end{table}

\subsubsection{Results Obtained}\label{subsubsec:umafall-results}

Casilari \textit{et al., 2018}~\cite{umafall} provided a dataset including 531 CSV files of which 322 were reporting daily activities data and 209 were reporting falls related data, each one of a 15-seconds duration. An initial analysis was performed in order to describe the variation of the \textbf{Signal Magnitude Vector} for each dataset.

Lastly, the results obtained determine substantial difficulties in distinguishing falls from moderate activities using threshold based techniques and propose an approach based on multiple sensors fusion and Machine Learning advances in order to reduce the number of \textbf{false positives} obtained. 

\subsection{UP-Fall Detection Dataset: A Multimodal Approach}\label{sec:upfall}

The \textbf{UP-Fall} dataset was presented in 2019 in order to collect fall-related information according to three major modalities:

\begin{itemize}
    \item \textbf{Wearable sensors}
    \item \textbf{Ambient sensors}
    \item \textbf{Vision devices}
\end{itemize}

The aim of the study was providing a considerable amount of data collected from heterogeneous sources in order to address the lack of publicly available measurements for the evaluation of fall detection systems \cite{upfall}.

\subsubsection{Technologies Involved}\label{subsubsec:upfall-technologies}

The hardware involved consisted of: 

\begin{itemize}
\item Five \textbf{Mbientlab MetaSensor} wearables located in different points of the body and collecting data from: 
    \begin{itemize}
        \item A 3-axis accelerometer
        \item A 3-axis gyroscope
        \item An ambient light sensor
    \end{itemize}
\item A \textbf{NeuroSky MindWave} electroencephalograph headset measuring the breainwave signal
\item Six \textbf{infrared sensor} forming a grid above the floor of the room
\item Two \textbf{Microsoft LifeCam Cinema} cameras providing a frontal and a lateral view of the user
\end{itemize}

The data gathering architecture was implemented through the usage of two computers and three Raspberry Pi V3 in order to collect the information from all the sensors and later save it in the form of multiple CSV files.

In this case a sample rate of \~ 18.4 Hz was configured in order to accommodate the requirements of all the units involved.

\subsubsection{Activities Performed}\label{subsubsec:upfall-activities}

The UP-Fall dataset was collected in a \textbf{controlled environment} where 17 young and healthy subjects were required to perform 11 different activities with three attempts each \cite{upfall}.

\begin{table}[H]
\centering
\begin{tabular}{ll}
    \hline
    Activity                          &   Category           \\
    \hline
    Walking                           &   Daily Activities   \\
    Standing                          &   Daily Activities   \\
    Sitting                           &   Daily Activities   \\
    Picking up an Object              &   Daily Activities   \\
    Laying                            &   Daily Activities   \\
    Jumping                           &   Daily Activities   \\
    Falling sitting in empty chair    &   Fall               \\
    Falling sideward                  &   Fall               \\
    Falling backwards                 &   Fall               \\
    Falling forwards using knees      &   Fall               \\
    Falling forwards using hands      &   Fall               \\
    \hline
\end{tabular}
\caption{Activities evaluated in UP-Fall}
\label{toc:umafall}
\end{table}

The raw gathered data was later divided in different time windows and, for each one of them, a \textbf{feature extraction and selection} process was performed. The processed information was, then, used to evaluate the performance of four classification models: 

\begin{itemize}
    \item Random Forest
    \item Support Vector Machines
    \item Multi-Layer Perceptron
    \item \textit{k}-Nearest Neighbors
\end{itemize}

The performances of the classification models were evaluated through the metrics of \textit{accuracy}, \textit{precision}, \textit{sensitivity}, \textit{specificity} and $F_1$ - \textit{score}.

A limitation pointed about by the authors \cite{umafall} involves the context of the experimentation: in fact, all the falls performed were self-initiated and different from real-life falls. These kind of aspects constitute a primary concern for researchers because of the difficulties in addressing them and the inaccuracy they might lead to, as stated in  \ref{sec:fallintro}.

\subsubsection{Results Obtained}\label{subsubsec:upfall-results}

The dataset obtained and the following activities (processing and analysis) performed led to observe that the data retrieved from the inertial measurement units of the wearables played a major role in the increase of accuracy. In fact, the accuracy (depicted by the $F_1$-score) of the IMUs-only based classification reached a value of 70.31\% while classifiers trained with combination of infrared and camera data demonstrated a considerably lower performance (between 15\% and 33\%). Lastly, the combination of data collected by the wearables, cameras and the EEG sensor obtained the highest $F_1$-score accuracy measure, which was equal to 70.44\%. 

Additionally, a Convolutional Neural Network was trained in order to improve the classification performance based on video recordings data. This reached an $F_1$-\textit{score} of 71.2\%.

In conclusion, in the context of fall detection systems, the analysis performed on the UP-Fall dataset demonstrated that a certain degree of accuracy may be reached by processing data from sources of different nature, even though classifications can be improved by approaching the subject in a multimodal and heterogeneous manner.

